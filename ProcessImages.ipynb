{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import misc\n",
    "from skimage.util import img_as_ubyte\n",
    "import fnmatch\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianFilter(image):\n",
    "    kernelsize = 3\n",
    "    gaussian1d = cv2.getGaussianKernel(kernelsize,0)\n",
    "    gaussian2d = (gaussian1d.T*gaussian1d)\n",
    "    image = cv2.filter2D(image, -1, gaussian2d)\n",
    "    image = cv2.normalize(image,None,0,255,cv2.NORM_MINMAX)\n",
    "    image = -image + np.max(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractRawChannels(image):\n",
    "    \n",
    "    # Raw images are arranged in a Bayer Filter pattern:\n",
    "    # B|G|B|G\n",
    "    # G|R|G|R\n",
    "    # B|G|B|G\n",
    "    # G|R|G|R\n",
    "    # By using the raw image instead of the color-processed image, we can get a higher spatial resolution\n",
    "    \n",
    "    # Zero out all green/blue pixels, smooth resultant image with a Gaussian kernel\n",
    "    red = image.copy()\n",
    "    red[0::2,1::2] = 0\n",
    "    red[1::2,:] = 0\n",
    "    red[:,:,1:]=0\n",
    "    #red = red - (np.max(red)/2)\n",
    "    #red[red < 0] = 0\n",
    "    #red = red.astype(np.uint8)\n",
    "    red[:,:,0] = GaussianFilter(red[:,:,0])\n",
    "    red = cv2.cvtColor(red,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Zero out all red/blue pixels, smooth resultant image with a Gaussian kernel\n",
    "    green = image.copy()\n",
    "    green[0::2,0::2] = 0\n",
    "    green[1::2,1::2] = 0\n",
    "    green[:,:,(0,2)]=0\n",
    "    #green = green - (np.max(green)/2)\n",
    "    #green[green < 0] = 0\n",
    "    #green = green.astype(np.uint8)\n",
    "    green[:,:,1] = GaussianFilter(green[:,:,1])\n",
    "    green = cv2.cvtColor(green,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Zero out all red/green pixels, smooth resultant image with a Gaussian kernel\n",
    "    blue = image.copy()\n",
    "    blue[0::2,:] = 0\n",
    "    blue[1::2,0::2] = 0\n",
    "    blue[:,:,:2]=0\n",
    "    #blue = blue - (np.max(blue)/2)\n",
    "    #blue[blue < 0] = 0\n",
    "    #blue = blue.astype(np.uint8)\n",
    "    blue[:,:,2] = GaussianFilter(blue[:,:,2])\n",
    "    blue = cv2.cvtColor(blue,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return red, green, blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'First Tests With Flow Chamber/Jan 26 2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(path) if file.endswith('tif')]\n",
    "\n",
    "if not os.path.exists(os.path.join(path,'Processed')):\n",
    "    os.makedirs(os.path.join(path,'Processed','ChannelExtracted'))\n",
    "    os.makedirs(os.path.join(path,'Processed','BackgroundRemoved'))\n",
    "    os.makedirs(os.path.join(path,'Processed','FlowAnalyzed'))\n",
    "    os.makedirs(os.path.join(path,'Processed','Particles'))\n",
    "\n",
    "for file in files:\n",
    "    name = file[:-4]\n",
    "    image = cv2.imread(os.path.join(path,file))\n",
    "    red, green, blue = ExtractRawChannels(image)\n",
    "    cv2.imwrite(os.path.join(path,'Processed','ChannelExtracted',name+'_red.tif'),red)\n",
    "    cv2.imwrite(os.path.join(path,'Processed','ChannelExtracted',name+'_green.tif'),green)\n",
    "    cv2.imwrite(os.path.join(path,'Processed','ChannelExtracted',name+'_blue.tif'),blue)\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background removal with SVD\n",
    "\n",
    "#Input Variables\n",
    "NumOfSubtractionModes = 1 #more modes means more time computing the SVD as well as doing background subtraction for each image\n",
    "NumOfImagesPerSVDCycle = 108 #len(files) #must be an exact divisor of the total number of images in each frame(i.e. the run was 1500 captures, use 100, 150, 300, 500, etc.)\n",
    "Frames = ['*red*','*green*','*blue*'] #Frame name keyphrases that it searches for\n",
    "\n",
    "\n",
    "os.system('cls' if os.name == 'nt' else 'clear')\n",
    "NumOfFrames = len(Frames)\n",
    "FileNames = sorted(os.listdir(os.path.join(path,'Processed','ChannelExtracted')))\n",
    "\n",
    "NumOfCycles = (len(FileNames)/(NumOfImagesPerSVDCycle*NumOfFrames))\n",
    "for CycleNumber in range(1,(np.floor(NumOfCycles)).astype(int) + 1): # Cycle through all the files in NumOfImagesPerSVDCycle increments, np.floor is for odd numbers of files that don't match multiples of NumImagesPerSVDCycle\n",
    "    CycleNames = FileNames[(((NumOfImagesPerSVDCycle*NumOfFrames)*CycleNumber)-(NumOfFrames*NumOfImagesPerSVDCycle)):((NumOfImagesPerSVDCycle*NumOfFrames)*CycleNumber)] #all the names for one cycle, read as 1LA,1LB,1RA,1RB,1TA,1TB,2LA,etc.\n",
    "    for frame in range(NumOfFrames): # Cycle through all the frames in a given cycle\n",
    "        FrameNames = fnmatch.filter(CycleNames,Frames[frame]) #find all the names for a given frame in the cycle\n",
    "        NumberofFiles = len(FrameNames)\n",
    "        ImageSize = np.shape(cv2.imread(os.path.join(path,'Processed','ChannelExtracted',FrameNames[0]))) #test the first image for size\n",
    "        ImageSize = ImageSize[0:2]\n",
    "        ImageVectors = np.empty([NumberofFiles,ImageSize[0] * ImageSize[1]],dtype=np.uint8) #initialization before loop\n",
    "        print(\"\\n--------------------------Reading Images---------------------------\\n\")\n",
    "        for ImageNumber in range(NumberofFiles):\n",
    "            print(\"Reading:\",FrameNames[ImageNumber])\n",
    "            image = cv2.imread(os.path.join(path,'Processed','ChannelExtracted',FrameNames[ImageNumber])).astype(np.uint8)\n",
    "            ImageVectors[ImageNumber,:] = (np.ravel(image[:,:,0],\"F\")) #ravel/vectorize each 2D image to 1D and insert into the 2D matrix \"ImageVectors\"\n",
    "        print(\"\\n-----------------Performing Sparse SVD Algorithm-------------------\\n\")\n",
    "        u, s, v = svds(csr_matrix.asfptype(np.transpose(ImageVectors)),k=NumOfSubtractionModes,which='LM')\n",
    "        um,sm,vm = np.asmatrix(u),np.asmatrix(s),np.asmatrix(v) #move to matrix data type for processing\n",
    "        del u,s,v #memory management\n",
    "        SingleImageModes = np.empty([NumOfSubtractionModes,ImageSize[0],ImageSize[1]]) #initialization before loop\n",
    "        print(\"\\n--------------------------Writing Images---------------------------\\n\")\n",
    "        for image in range(NumOfImagesPerSVDCycle):\n",
    "            for modes in range(NumOfSubtractionModes):\n",
    "                SingleImageModes[modes,:,:] = np.reshape(um[:,modes] * sm[:,modes] * vm[modes,image],[ImageSize[0],ImageSize[1]],order=\"F\") #reshape the modes back into a stack of 2D background images\n",
    "            FilteredImage = np.reshape(np.transpose(ImageVectors[image,:]),[ImageSize[0],ImageSize[1]],order=\"F\") - np.sum(SingleImageModes,axis=0) #subtract the sum of all background modes from the original image\n",
    "            FilteredImage[FilteredImage < 0] = 0 #clean up/delete all negative values, as those will wrap around when saving it in unsigned byte format\n",
    "            STDFilter = 10*np.std(FilteredImage[FilteredImage != 0]) #10 is chosen arbitrarily for the data, it seems to work well for PIV data\n",
    "            FilteredImage[FilteredImage > STDFilter] = STDFilter #remove all values that are greater than the standard deviation based filter (this helps to eliminate glare points in the image)\n",
    "            print(\"Writing:\",FrameNames[image])\n",
    "            FilteredImage = FilteredImage / np.max(FilteredImage)\n",
    "            cv2.imwrite(os.path.join(path,'Processed','BackgroundRemoved',FrameNames[image]),img_as_ubyte(FilteredImage)) #save the image in byte format\n",
    "    timeleft = (time.clock() * ((np.floor(NumOfCycles)*NumOfFrames) / ( ((CycleNumber-1)*NumOfFrames)+(frame+1) )))-time.clock()\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')\n",
    "    print(\"\\nTime to completion:\",format(timeleft/60, '.4f'),\"minutes\")\n",
    "print('\\n\\n\\nFinished! :)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectBlobs(image):\n",
    "    # Set our filtering parameters \n",
    "    # Initialize parameter settiing using cv2.SimpleBlobDetector \n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "    # Set Color filtering parameter\n",
    "    params.filterByColor = True\n",
    "    params.blobColor = 255\n",
    "\n",
    "    # Set Area filtering parameters \n",
    "    params.filterByArea = True\n",
    "    params.minArea = 25\n",
    "    params.maxArea = 10000\n",
    "\n",
    "    # Set Circularity filtering parameters \n",
    "    params.filterByCircularity = True \n",
    "    params.minCircularity = 0.2\n",
    "    params.maxCircularity = 1\n",
    "\n",
    "    # Set Convexity filtering parameters \n",
    "    params.filterByConvexity = True\n",
    "    params.minConvexity = 0.2\n",
    "    params.maxConvexity = 1\n",
    "\n",
    "    # Set Inertia filtering parameters \n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = 0.2\n",
    "    params.maxInertiaRatio = 1\n",
    "    \n",
    "    # Set Threshold filtering parameters\n",
    "    params.minThreshold = np.mean(image)*0.5\n",
    "    params.maxThreshold = 255\n",
    "    params.thresholdStep = params.maxThreshold / 20\n",
    "\n",
    "    # Create a detector with the parameters \n",
    "    detector = cv2.SimpleBlobDetector_create(params) \n",
    "    # Detect blobs \n",
    "    keypoints = detector.detect(cv2.cvtColor(image,cv2.COLOR_BGR2GRAY))\n",
    "    points = [keypoints[idx].pt for idx in range(0, len(keypoints))]\n",
    "    blank = np.zeros((1,1))\n",
    "    blobsimage = cv2.drawKeypoints(image*0, keypoints, blank, (255,0,0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    return blobsimage, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(os.path.join(path,'Processed','BackgroundRemoved')):\n",
    "    name = file[:-4]\n",
    "    image = cv2.imread(os.path.join(path,'Processed','BackgroundRemoved',file))\n",
    "    blobimage, points = DetectBlobs(image)\n",
    "    number_of_blobs = len(points) \n",
    "    text = \"Number of Blobs: \" + str(len(points)) \n",
    "    cv2.putText(blobimage, text, (20, 550), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 100, 255), 2) \n",
    "    plt.imsave(os.path.join(path,'Processed','Particles',name+'.tif'),blobimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flow_List = []\n",
    "Acceleration_List = []\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 1000,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (40,40),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(1000,3))\n",
    "\n",
    "background_removed_path = os.path.join(path,'Processed','BackgroundRemoved')\n",
    "files = [file for file in os.listdir(background_removed_path) if 'red' in file]\n",
    "for file in files[0:100]:\n",
    "    print(file)\n",
    "    red_path = background_removed_path+'/'+file[:-7]+'red.tif'\n",
    "    green_path = background_removed_path+'/'+file[:-7]+'green.tif'\n",
    "    blue_path = background_removed_path+'/'+file[:-7]+'blue.tif'\n",
    "    red = cv2.cvtColor(cv2.imread(red_path),cv2.COLOR_BGR2GRAY)\n",
    "    green = cv2.cvtColor(cv2.imread(green_path),cv2.COLOR_BGR2GRAY)\n",
    "    blue = cv2.cvtColor(cv2.imread(blue_path),cv2.COLOR_BGR2GRAY)\n",
    "    channel_images = [red,green,blue]\n",
    "    \n",
    "    #p0 = cv2.goodFeaturesToTrack(channel_images[0], mask = None, **feature_params)\n",
    "\n",
    "    # Create a mask image for drawing purposes\n",
    "    #mask = np.zeros_like(channel_images[0])\n",
    "\n",
    "\n",
    "    #hsv = np.zeros_like(cv2.imread(red_path))\n",
    "    #hsv[...,1] = 255\n",
    "    \n",
    "    \n",
    "    for channel in range(2):\n",
    "        \n",
    "        # calculate optical flow\n",
    "\n",
    "        flow = cv2.calcOpticalFlowFarneback(channel_images[channel], channel_images[channel+1], None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        #mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        #hsv[...,0] = ang #*180/np.pi/2\n",
    "        #hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "        #rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        Flow_List.append(flow)\n",
    "        \n",
    "        '''\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(channel_images[channel], channel_images[channel+1], p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "        # draw the tracks\n",
    "        for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "            a,b = new.ravel()\n",
    "            c,d = old.ravel()\n",
    "            mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(channel_images[channel],(a,b),5,color[i].tolist(),-1)\n",
    "        img = cv2.add(channel_images[channel],mask)\n",
    "\n",
    "        # Now update the previous frame and previous points\n",
    "        p0 = good_new.reshape(-1,1,2)\n",
    "        '''\n",
    "\n",
    "    #plt.imsave(os.path.join(path,'Processed','FlowAnalyzed',file[:-7]+'FlowField.tif'),rgb)\n",
    "    #plt.imsave(os.path.join(path,'Processed','Particles',file[:-7]+'ParticleTracks.tif'),mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flow_Average = np.max(Flow_List,axis=0)\n",
    "mag, ang = cv2.cartToPolar(Flow_Average[...,0], Flow_Average[...,1])\n",
    "hsv = np.zeros_like(cv2.imread(red_path))\n",
    "hsv[...,1] = 255\n",
    "hsv[...,0] = ang #*180/np.pi/2\n",
    "hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "plt.imsave(os.path.join(path,'Processed','FlowAnalyzed','FlowAverage.tif'),rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "path = 'LED Flash Timing/Jan 23 2021 Dual RGB Flash'\n",
    "files = [file for file in os.listdir(path) if file.endswith('tif')]\n",
    "for file in files:\n",
    "    name = file[:-4]\n",
    "    if '12809' in name:\n",
    "        print(os.path.join(path,file))\n",
    "        image = cv2.imread(os.path.join(path,file))\n",
    "        red, green, blue = ExtractRawChannels(image)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_vec = image.ravel()\n",
    "red_vec = red.ravel()\n",
    "green_vec = green.ravel()\n",
    "blue_vec = blue.ravel()\n",
    "\n",
    "RGB_vectorized = np.array([image_vec,red_vec,green_vec,blue_vec]).T\n",
    "print(RGB_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import FastICA\n",
    "X, _ = load_digits(return_X_y=True)\n",
    "transformer = FastICA(n_components=4,random_state=0)\n",
    "RGB_separated = transformer.fit_transform(RGB_vectorized)\n",
    "RGB_separated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vec = RGB_separated[:,0]\n",
    "red_vec = RGB_separated[:,1]\n",
    "green_vec = RGB_separated[:,2]\n",
    "blue_vec = RGB_separated[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_separated = np.reshape(image_vec,image.shape)\n",
    "red_separated = np.reshape(red_vec,red.shape)\n",
    "green_separated = np.reshape(green_vec,green.shape)\n",
    "blue_separated = np.reshape(blue_vec,blue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(path+'/Separated0.tif',cv2.normalize(image_separated,None,0,255,cv2.NORM_MINMAX).astype(np.uint8))\n",
    "cv2.imwrite(path+'/Separated1.tif',cv2.normalize(red_separated,None,0,255,cv2.NORM_MINMAX).astype(np.uint8))\n",
    "cv2.imwrite(path+'/Separated2.tif',cv2.normalize(green_separated,None,0,255,cv2.NORM_MINMAX).astype(np.uint8))\n",
    "cv2.imwrite(path+'/Separated3.tif',cv2.normalize(blue_separated,None,0,255,cv2.NORM_MINMAX).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
